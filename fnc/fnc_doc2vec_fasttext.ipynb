{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import score as s\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_bodies = pd.read_csv('fnc/train_bodies.csv')\n",
    "train_stances = pd.read_csv('fnc/train_stances.csv')\n",
    "train = train_stances.merge(train_bodies, on='Body ID')\n",
    "\n",
    "test_bodies = pd.read_csv('fnc/competition_test_bodies.csv')\n",
    "test_stances = pd.read_csv('fnc/competition_test_stances.csv')\n",
    "test = test_stances.merge(test_bodies, on='Body ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fasttext skipgram requires text file as input \n",
    "train_bd = train['articleBody']\n",
    "train_headline = train['Headline']\n",
    "test_bd = test['articleBody']\n",
    "test_headline = test['Headline']\n",
    "all_texts = np.concatenate((train_bd, train_headline, test_bd, test_headline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('fnc/texts.txt', 'w') as f:\n",
    "    f.writelines(all_texts)\n",
    "    \n",
    "word2vec = fasttext.skipgram('fnc/texts.txt', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc2vec(tokens, word2vec):\n",
    "    word_vecs = np.array([word2vec[token] for token in tokens])\n",
    "    vec = normalize(word_vecs).mean(axis=0)\n",
    "    assert len(vec) == 100\n",
    "    return vec\n",
    "\n",
    "def get_tokens(text, stopwords, tokenizer):\n",
    "    return list(filter(lambda x: x not in stopwords, tokenizer(text)))\n",
    "\n",
    "def get_vectors(df, word2vec):\n",
    "    sw = stopwords.words('english')\n",
    "    headline_vecs = np.array(list(map(lambda text: doc2vec(get_tokens(text, sw, word_tokenize), word2vec), df['Headline'])))\n",
    "    body_vecs = np.array(list(map(lambda text: doc2vec(get_tokens(text, sw, word_tokenize), word2vec), df['articleBody'])))\n",
    "    return headline_vecs, body_vecs\n",
    "\n",
    "train_headline_vectors, train_body_vectors = get_vectors(train, word2vec)\n",
    "test_headline_vectors, test_body_vectors = get_vectors(test, word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cosine = np.array(list(map(lambda a: cosine_similarity(a[0].reshape(1, -1),a[1].reshape(1, -1))[0,0], zip(train_headline_vectors, train_body_vectors))))\n",
    "test_cosine = np.array(list(map(lambda a: cosine_similarity(a[0].reshape(1, -1),a[1].reshape(1, -1))[0,0], zip(test_headline_vectors, test_body_vectors))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label(n):\n",
    "    if n == \"agree\": return 0.0\n",
    "    if n == \"discuss\": return 1.0\n",
    "    if n == \"disagree\": return 2.0\n",
    "    if n == \"unrelated\": return 3.0\n",
    "    \n",
    "def unlabel(n):\n",
    "    if n == 0.0: return \"agree\"\n",
    "    if n == 1.0: return \"discuss\"\n",
    "    if n == 2.0: return \"disagree\"\n",
    "    if n == 3.0: return \"unrelated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced')\n",
    "x_train = np.hstack((train_headline_vectors, train_body_vectors, np.expand_dims(train_cosine, axis=1)))\n",
    "y_train = train.apply(lambda row: label(row['Stance']), axis=1)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85365757683075594"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.hstack([test_headline_vectors, test_body_vectors, np.expand_dims(test_cosine, axis=1)])\n",
    "y_test = test.apply(lambda row: label(row['Stance']), axis=1)\n",
    "y_prediction = model.predict(x_test)\n",
    "accuracy_score(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    867    |    93     |    431    |    512    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    197    |    69     |    117    |    314    |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    501    |    342    |   2828    |    793    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    84     |    43     |    292    |   17930   |\n",
      "-------------------------------------------------------------\n",
      "Score: 8666.75 out of 11651.25\t(74.3847226692415%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.3847226692415"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = list(test['Stance'])\n",
    "predicted = list(map(lambda x: unlabel(x), y_prediction))\n",
    "s.report_score(actual, predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
