{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import *\n",
    "import random as rnd\n",
    "import os\n",
    "import math as m\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-07-05 18:48:54--  http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4573338 (4.4M) [text/plain]\n",
      "Saving to: ‘shakespeare_input.txt’\n",
      "\n",
      "shakespeare_input.t 100%[===================>]   4.36M  1.38MB/s    in 3.2s    \n",
      "\n",
      "2017-07-05 18:48:58 (1.38 MB/s) - ‘shakespeare_input.txt’ saved [4573338/4573338]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
    "!mv shakespeare_input.txt data/shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'data/shakespeare_input.txt'\n",
    "with open(fname, 'r') as f:\n",
    "    data = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NgramLanguageModel():\n",
    "    def __init__(self, n):\n",
    "        self.n = n\n",
    "    \n",
    "    def train(self, data_entries):\n",
    "        self.lm = defaultdict(Counter)\n",
    "        \n",
    "        self.unigram_lm = self._train_unigram(data_entries)\n",
    "        \n",
    "        for n in range(2, self.n+1):\n",
    "            self._train_ngram(data_entries, n)\n",
    "            \n",
    "        def normalize(counter):\n",
    "            s = float(sum(counter.values()))\n",
    "            return {c:cnt/s for c,cnt in counter.items()}\n",
    "        \n",
    "        self.lm = {hist:normalize(chars) for hist, chars in self.lm.items()}\n",
    "        return self\n",
    "    \n",
    "    def generate(self, max_len=1000, seed = None):\n",
    "        rnd.seed(seed)\n",
    "        prev = '~'*(self.n-1)\n",
    "        result = ''\n",
    "\n",
    "        for i in range(max_len):\n",
    "            if len(prev) == 0:\n",
    "                apriori_char_probs = self.unigram_lm\n",
    "                \n",
    "            # if ngram model not found, try to find n-1\n",
    "            elif prev not in self.lm: \n",
    "                prev = prev[1:]\n",
    "                continue\n",
    "            else:\n",
    "                apriori_char_probs = self.lm[prev]\n",
    "\n",
    "            char = self._generate_random_char(apriori_char_probs)\n",
    "            if(char == \"~\"): break\n",
    "\n",
    "            result += char\n",
    "            prev = prev[1:] + char\n",
    "\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def _train_ngram(self, data_entries, n):\n",
    "        order = n-1\n",
    "        pad = \"~\" * order\n",
    "        for data in data_entries:\n",
    "            data = pad + data + pad\n",
    "\n",
    "            for i in range(len(data) - order):\n",
    "                history, char = data[i:i+order], data[i+order]\n",
    "                self.lm[history][char]+=1\n",
    "    \n",
    "    def _train_unigram(self, data_entries):\n",
    "        data = '\\n'.join(data_entries)\n",
    "        return { c:data.count(c)/len(data_entries) for c in set(data_entries) }\n",
    "    \n",
    "    def _generate_random_char(self, apriori_char_probs):\n",
    "        random_point = rnd.random()\n",
    "        s = 0\n",
    "        for char, proba in apriori_char_probs.items():\n",
    "            s += proba\n",
    "            if s > random_point: return char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NgramLanguageModel at 0x7fdf2eb181d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_model = NgramLanguageModel(5)\n",
    "shakespeare_model.train([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first may be that well, your treates a walked withal.\n",
      "set me, death, he in the worsed fathere i this wick, he daugh you aim.\n",
      "\n",
      "against pursula:\n",
      "thou and a rome gamemnon:\n",
      "ay, bondman,\n",
      "or even\n",
      "the deceived her, i will unce:\n",
      "do:\n",
      "what to de arrant, like\n",
      "quicked; for thane immortime gone, thy lord; and how note;\n",
      "lest i seek thee with that thoughter trivil happy what in angel; if it madam.\n",
      "\n",
      "samplexion, that we hand:\n",
      "a' could i never together affet guiled too bidding fair, hear thy stake a king rises of you, adies' hear?\n",
      "know the knight deathing natural of that thought thou banquo:\n",
      "yes, that, tempt follop tent.\n",
      "i sayer:\n",
      "what now not i myself. the ape,\n",
      "thou look you are at 'tis he thou in the curity, and of york to hellow me, a fly, which golden cascals?\n",
      "\n",
      "secontent'st the fiery are body.'\n",
      "\n",
      "king his amonger at on his the percy, sir; i are fleet, that falstaff:\n",
      "were ample toward:\n",
      "go for with an is straitor trojan, good moe whose eye.\n",
      "\n",
      "nerish.\n",
      "\n",
      "queens to makes upon the duke's gone;\n",
      "my harm off of \n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_model.generate(max_len=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try Stus poetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        return f.read().lower()\n",
    "    \n",
    "def preprocess(poem):\n",
    "    # left only meaningful symbols\n",
    "    poem = re.sub('[^!а-яіїєА-ЯІЇЄ\\s\\,\\.\\-\\—\\:\\n\\!\\(\\)\\?’`\\']', '', poem)\n",
    "    return poem.replace('\\t', '\\n')\n",
    "\n",
    "folder = 'data/stus/'\n",
    "stus_poetry = [preprocess(poem) for fname in os.listdir(folder) for poem in readfile(folder+fname).split('|')]\n",
    "all_text = '\\n'.join(stus_poetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NgramLanguageModel at 0x7fdf2c591dd8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stus_model = NgramLanguageModel(9)\n",
    "stus_model.train(stus_poetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "не можу дати ради\n",
      "жарина біла ув огні огнів.\n",
      "а все життя моє прожив,\n",
      "на многотрудне\n",
      "те серце, облягла\n",
      "рілля жорстока розплатались\n",
      "в тисячі твоїх смертей\n",
      "тобі услід? ачи твою подобу\n",
      "стисненої пружини.\n",
      "долучений до твого живоття.\n",
      "а як же приязнь? що то є любов?\n",
      "то рівновеликі\n",
      "оці зусилля\n",
      "і сни мене веде, а час мене жене\n",
      "і промигцем горить стерня, де половіло жито,\n",
      "о вересню, теребище смеркань.\n",
      "путі — задовгі і загострі,\n",
      "неначе свічка. врочить порив: не спиняйся, йди.\n",
      "то шлях проліг нам — у просторить сосна — од низу до гори.\n",
      "горить свічку.\n",
      "поштурхай дрова в грубі, в філіжанку,\n",
      "в якої пооббивано краї.\n",
      "в яскиню сну не наполовину,\n",
      "наполовину,\n",
      "наполовину знане і незнайомі.\n",
      "повсідались на житній соломі,\n",
      "на трипільська,\n",
      "і креше душу відпустила в лет\n",
      "і вірш твій вирвався з тіла.\n",
      "бо унизу — як лезо рів\n",
      "зі спиртом вод. та бог боронить.\n",
      "бери у праці втому і печаль,\n",
      "глибій у радості воскрес.\n",
      "геть обвішаний медалями,\n",
      "лишився в жили віт,\n",
      "а вже і край.\n",
      "коли кортить на всьому. тож ступай, допоки не поч\n"
     ]
    }
   ],
   "source": [
    "poem = stus_model.generate()\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to check the maximum block used from original corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plagiarism_check(text, big_text):\n",
    "    for window_size in reversed(range(int(len(text)/10))):\n",
    "        for window_start in range(len(text)-window_size):\n",
    "            window_text = text[window_start:window_start + window_size]\n",
    "            index = big_text.find(window_text)\n",
    "\n",
    "            if(index > -1):\n",
    "                s = max(index, 0)\n",
    "                e = min(index + window_size, len(big_text))\n",
    "                print(\"Plagiarism found: {}\".format(big_text[s:e]))\n",
    "                return window_size\n",
    "    return 0\n",
    "\n",
    "plagiarism_check(poem, all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
