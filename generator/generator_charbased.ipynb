{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import *\n",
    "import random as rnd\n",
    "import os\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-07-05 11:01:56--  http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4573338 (4.4M) [text/plain]\n",
      "Saving to: ‘shakespeare_input.txt’\n",
      "\n",
      "shakespeare_input.t 100%[===================>]   4.36M  1.09MB/s    in 4.9s    \n",
      "\n",
      "2017-07-05 11:02:01 (913 KB/s) - ‘shakespeare_input.txt’ saved [4573338/4573338]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
    "!mv shakespeare_input.txt generation/shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'generation/shakespeare_input.txt'\n",
    "with open(fname, 'r') as f:\n",
    "    data = f.read().lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_ngram_char_lm(datas, n=5):\n",
    "    order = n-1\n",
    "    lm = defaultdict(Counter)\n",
    "    pad = \"~\" * order\n",
    "    for data in datas:\n",
    "        data = pad + data + pad\n",
    "\n",
    "        for i in range(len(data) - order):\n",
    "            history, char = data[i:i+order], data[i+order]\n",
    "            lm[history][char]+=1\n",
    "        \n",
    "    def normalize(counter):\n",
    "        s = float(sum(counter.values()))\n",
    "        return {c:cnt/s for c,cnt in counter.items()}\n",
    "    \n",
    "    outlm = {hist:normalize(chars) for hist, chars in lm.items()}\n",
    "    return outlm\n",
    "\n",
    "def train_unigram_char_lm(datas):\n",
    "    data = '\\n'.join(datas)\n",
    "    return { c:data.count(c)/len(data) for c in set(data) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_model = train_unigram_char_lm([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_model = train_ngram_char_lm([data], n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random(apriori_char_probs):\n",
    "    random_point = rnd.random()\n",
    "    s = 0\n",
    "    for char, proba in apriori_char_probs.items():\n",
    "        s += proba\n",
    "        if s > random_point: return char\n",
    "\n",
    "def generate(model, n, max_len=1000, seed = None, unigram_model = None):\n",
    "    rnd.seed(seed)\n",
    "    prev = '~'*(n-1)\n",
    "    result = ''\n",
    "    i = 0\n",
    "    while(True):\n",
    "        i += 1\n",
    "        if n == 1:\n",
    "            apriori_char_probs = model\n",
    "        else:\n",
    "            apriori_char_probs = model[prev]\n",
    "            \n",
    "        char = generate_random(apriori_char_probs)\n",
    "        if(char == \"~\" or i > max_len): break\n",
    "            \n",
    "        result += char\n",
    "        prev = prev[1:] + char\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first loved,\n",
      "saving in his for should to\n",
      "me on.\n",
      "\n",
      "claudio:\n",
      "look you speaking! i hath the quiet, oft f\n"
     ]
    }
   ],
   "source": [
    "print(generate(five_model, 5, max_len=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try Stus poetry\n",
    "def readfile(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        return f.read().lower()\n",
    "    \n",
    "def preprocess(poem):\n",
    "    return poem.replace('\\t', ' ')\n",
    "    \n",
    "\n",
    "folder = 'generation/stus/'\n",
    "stus_poetry = [preprocess(poem) for fname in os.listdir(folder) for poem in readfile(folder+fname).split('|')]\n",
    "all_text = '\\n'.join(stus_poetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stus_big_model = train_ngram_char_lm(stus_poetry, n=10)\n",
    "stus_unigram_model = train_unigram_char_lm(stus_poetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿ несуть в руках, пропахлі небуттям.\n",
      "світ твориться і міниться, мов око\n",
      "побожеволілі, знечулі\n",
      "чотири мури,\n",
      "три двері, ґрачене вікно,\n",
      "в якому районі міста\n",
      "пленуми проводять нас поранні дзвони від грузькому\n",
      "скотилися повільно побивала. слава богу,\n",
      "пізнавши вочевидь: любов,\n",
      "як і життя — не одійду за сталою\n",
      "імлою, за збіглим сном під чорною ганьбою,\n",
      "межи слідами чорних спроб, і кожна хвиля\n",
      "у берегах, мов голуба, пустила в лет\n",
      "там, де чотири вітри,\n",
      "ласкаві ластівки на електричних дротах,\n",
      "почорнілий пень підкаже,\n",
      "де знайти загублена в міжпланетарній пустці —\n",
      "в’язниця, що донесла з говерли\n",
      "тривожні породіль. нема одвіку\n",
      "легкої віри і легких утіх.\n"
     ]
    }
   ],
   "source": [
    "poem = generate(stus_big_model, 10, unigram_model=stus_unigram_model)\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plagiarism_check(text, big_text, window_size):\n",
    "    for window_start in range(len(text)-window_size):\n",
    "        window_text = text[window_start:window_start + window_size]\n",
    "        index = big_text.find(window_text)\n",
    "        \n",
    "        if(index > -1):\n",
    "            s = max(index, 0)\n",
    "            e = min(index + window_size, len(big_text))\n",
    "            print(\"Plagiarism found: {}\".format(big_text[s:e]))\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "plagiarism_check(poem, all_text, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
